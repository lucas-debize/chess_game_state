{
    "name": "basic_network",
    "layers": [64, 512, 256, 128, 64, 6],
    "activation_hidden": "relu",
    "activation_output": "softmax",
    "optimizer": "sgd",
    "learning_rate": 0.0005,
    "batch_size": 64,
    "dropout_rate": 0.3,
    "momentum": 0.9,
    "beta1": 0.9,
    "beta2": 0.999,
    "epsilon": 1e-8,
    "l2_lambda": 0.01
}
